{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73f4afc82ac5eb796497b27661b2e64e",
     "grade": false,
     "grade_id": "cell-ae30484898a90983",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b966d402a5a70fab19daf7aceb6e6fbe",
     "grade": false,
     "grade_id": "cell-76f53f536a715153",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is programming assignment for week 5. In this assignment you will be solving classification task. \n",
    "\n",
    "### Grading\n",
    "The assignment contains both automatically graded and peer reviewed tasks. \n",
    "\n",
    "**Automatic grading**\\\n",
    "After you finish solving all the tasks restart the kernel (`kernel -> restart`) and and click button `Validate` to check that everything works as expected. Afterwards, you can submit your work.\n",
    "\n",
    "\n",
    "\n",
    "**Peer Review**\\\n",
    "Some of the tasks cannot be checked automatically,  therefore, we'll be using peer review. Please, download this notebook with solutions (`File → Download as → Notebook (.ipynb)`) and submit it for peer review. Each peer reviewed task contains grading instructions. \n",
    "\n",
    "\n",
    "\n",
    "## Part 1. Let's train some decision trees. <a class=\"anchor\" id=\"part1\"></a>\n",
    "\n",
    "In this part, we will do the simplest preprocessig of the dataset and train decision trees. In the task, you are supposed to predict whether income of a person exceeds \\$50K/year. The target variable is equal to `1` if a person earns > \\$50k/year and `0` otherwise. \n",
    "\n",
    "As an evaluation criterion, we will be using $F_1$score. As you know, it is a weighted average of precision and recall. We are not using accuracy, because the dataset is imbalanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2247f6fbdeacd1a3b5d7fd85a425048",
     "grade": false,
     "grade_id": "cell-1a1e843b43cccdb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('https://github.com/mbburova/MDS/raw/main/week5_train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d49a747054b4f1419b46fe18822bee7d",
     "grade": false,
     "grade_id": "cell-84c65c97c89f7c75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr, val = train_test_split(train_data, test_size=0.4, random_state=42)\n",
    "\n",
    "y_train = tr.target\n",
    "y_valid = val.target\n",
    "X_train = tr.drop(['target'], axis=1)\n",
    "X_valid = val.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "210b94f03d658eb2f945598cff06fb60",
     "grade": false,
     "grade_id": "cell-cfd6b8c9e0a01674",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task1\"></a>\n",
    "\n",
    "---\n",
    "**Task 1** [1 pt] Create `column_transformer` which has the following steps:\n",
    "- fills all the missing values \n",
    "- encodes all the categorical features using OHE \n",
    "- scales numerical features.\n",
    "\n",
    "P.S. note, that you'll have to import all the required modules yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7a8657187d0724ac6605b1401b40d9c",
     "grade": false,
     "grade_id": "cell-72d8346d6028cb1d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36c9c5802ffe52fa0a21f3cc0bc41e93",
     "grade": true,
     "grade_id": "cell-183f2ac417f75d76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_transformed = column_transformer.fit_transform(X_train)\n",
    "X_transformed.shape\n",
    "\n",
    "X_transformed = column_transformer.fit_transform(X_train)\n",
    "assert X_transformed.shape[0] == 19536\n",
    "assert X_transformed.shape[1] == 104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0d7f88a9241e795223a173c45a51f03",
     "grade": false,
     "grade_id": "cell-fb4d3801b5f35b11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task2\"></a>\n",
    "\n",
    "---\n",
    "**Task 2** [1 pt] Create a function `tree_pipe`, which given a maximal tree depth returns a pipeline with two steps:\n",
    "\n",
    "1. Column transformer (defined above)\n",
    "2. DecisionTreeClassfier with the required `max_depth` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3862785750a99944c053f9d5e0b8b339",
     "grade": false,
     "grade_id": "cell-b9de0824900552ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def tree_pipe(max_depth):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e60c8560b3230266728aba428e5a9337",
     "grade": true,
     "grade_id": "cell-c542e20f3e709f98",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_pipe = tree_pipe(1)\n",
    "\n",
    "test_pipe = tree_pipe(12)\n",
    "tree = test_pipe.steps[1][1]\n",
    "assert tree.max_depth == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf6de67039590f3d54c06be163f3d152",
     "grade": false,
     "grade_id": "cell-52d80521f0a0cbf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"task3\"></a>\n",
    "\n",
    "---\n",
    "**Task 3** [Peer Reviewed] Fit decision trees of different depth (from 1 to 100) using the function from the **task 2**. For each depth calculate $F_1$score on the train and validation datasets. Draw a plot, how both scores depend on the maximal tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a6226b71197ff52bd4da78c2060b6c4",
     "grade": false,
     "grade_id": "cell-d9d8ea084313b76d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c0de7b5576d63c76a04fccd52f15512",
     "grade": true,
     "grade_id": "cell-8d7c2fabbc41326a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Let's compete. <a class=\"anchor\" id=\"part2\"></a>\n",
    "\n",
    "In this second part of the assignment your task will be straightforward: achieve the best possible score on the test set. To make everything fair, we will be using [Kaggle competition](https://www.kaggle.com/c/predict-income-group). \n",
    "\n",
    "At this stage you are free to use any models or preprocessing methods you want. You can use assignemnts from the previous weeks as an inspiration!\n",
    "\n",
    "Below you can see how the test dataset can be loaded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('https://github.com/mbburova/MDS/raw/main/week5_test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PREPROCESSING AND MODELS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not forget to save your predictions on test and submit them on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see, how `csv` file with the prediction can be created and saved. This file can be later used to upload to Kaggle. Please note, that type of the prediction should be `integer`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we do not restrict you a lot in this task, we still ask you to stick to the following steps, which will be graded by your peers\n",
    "\n",
    "**Peer Review Grading.** Below you will find the list of criteria for peer review:\n",
    "1. Consider categorical features. Show which feature are categorical, check if all the categories are reasonable. Provide plots.\n",
    "2. Consider numerical features\n",
    "3. Fill missing values. \n",
    "4. Explore different hyperparameters of the decision trees (not only `max_depth`)\n",
    "5. Choose the best model using cross-validation or just validation\n",
    "6. Make a prediction on the test set.\n",
    "7. Try to make your code readable. Do not forget to leave comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
